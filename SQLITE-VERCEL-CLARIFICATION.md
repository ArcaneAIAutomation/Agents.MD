# SQLite on Vercel - Important Clarification

**Date**: November 8, 2025  
**Status**: âš ï¸ **IMPORTANT CORRECTION**

---

## âŒ SQLite Does NOT Work on Vercel

### The Problem:

**SQLite is NOT compatible with Vercel's serverless architecture.**

### Why It Doesn't Work:

1. **Stateless Functions**
   - Each Vercel function runs in an isolated container
   - No persistent file system between invocations
   - Database file is lost after each request

2. **Read-Only File System**
   - Vercel functions have read-only file systems
   - Only `/tmp` is writable (and it's cleared between invocations)
   - SQLite needs to write to disk

3. **No Shared State**
   - Multiple function instances can't share the same file
   - Each instance would have its own isolated database
   - No data synchronization between instances

4. **Cold Starts**
   - Functions spin down when idle
   - Database file would be recreated on each cold start
   - All cached data would be lost

---

## âœ… What the SQLite MCP Server Is For

### Local Development Only:

The SQLite MCP server configured in `.kiro/settings/mcp.json` is **ONLY for local development**:

- âœ… Works in Kiro IDE on your local machine
- âœ… Great for development and testing
- âœ… Fast local caching during development
- âŒ **NOT for production/Vercel**
- âŒ **NOT deployed to Vercel**

**Location**: `C:\OriK.Projects\Agents.MD\Agents.MD\data\cache.db`  
**Scope**: Local machine only  
**Purpose**: Development convenience

---

## âœ… Correct Caching Strategy for Vercel

### You Already Have the Perfect Setup! ğŸ‰

### 1. **Upstash Redis** â­ (Primary Cache)

**Status**: âœ… Already configured and working  
**Perfect For**: Production caching on Vercel

**Why Redis is Perfect**:
- âœ… Serverless-compatible (HTTP REST API)
- âœ… Shared across all function instances
- âœ… Persistent data storage
- âœ… Fast (sub-millisecond latency)
- âœ… Built-in TTL (time-to-live)
- âœ… Free tier: 10,000 commands/day

**Current Configuration**:
```bash
UPSTASH_REDIS_REST_URL=https://musical-cattle-22790.upstash.io
UPSTASH_REDIS_REST_TOKEN=AVkGAAIncDIyOTYyY2RhZGViNTg0ODI5OWQ1ZWVmN2ZjNjBhMTlkM3AyMjI3OTA
```

**Usage Example**:
```typescript
import { Redis } from '@upstash/redis';

const redis = new Redis({
  url: process.env.UPSTASH_REDIS_REST_URL!,
  token: process.env.UPSTASH_REDIS_REST_TOKEN!,
});

// Cache API response (5 minute TTL)
await redis.set('btc:price', 
  { price: 101659, timestamp: Date.now() }, 
  { ex: 300 }
);

// Get cached data
const cached = await redis.get('btc:price');
if (cached) {
  return cached; // Use cache
}

// Fetch fresh data if cache miss
const fresh = await fetchFromAPI();
await redis.set('btc:price', fresh, { ex: 300 });
return fresh;
```

---

### 2. **PostgreSQL (Supabase)** (Secondary Cache)

**Status**: âœ… Already configured and working  
**Perfect For**: Longer-term caching and historical data

**Why PostgreSQL Works**:
- âœ… Persistent storage
- âœ… Shared across all instances
- âœ… Complex queries
- âœ… Relational data
- âœ… Already configured

**Usage Example**:
```typescript
// Create cache table (run once)
CREATE TABLE api_cache (
  key TEXT PRIMARY KEY,
  value JSONB,
  created_at TIMESTAMP DEFAULT NOW(),
  expires_at TIMESTAMP
);

CREATE INDEX idx_api_cache_expires ON api_cache(expires_at);

// Cache data
await query(
  `INSERT INTO api_cache (key, value, expires_at) 
   VALUES ($1, $2, NOW() + INTERVAL '5 minutes')
   ON CONFLICT (key) DO UPDATE SET value = $2, expires_at = NOW() + INTERVAL '5 minutes'`,
  ['btc:price', JSON.stringify({ price: 101659 })]
);

// Get cached data
const result = await query(
  `SELECT value FROM api_cache 
   WHERE key = $1 AND expires_at > NOW()`,
  ['btc:price']
);
```

---

## ğŸ“Š Recommended Caching Architecture

### Three-Tier Caching Strategy:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Vercel Production                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                          â”‚
â”‚  1. Memory Cache (In-Function)                          â”‚
â”‚     â””â”€ Duration: Single request only                    â”‚
â”‚     â””â”€ Use: Avoid duplicate API calls in same request   â”‚
â”‚                                                          â”‚
â”‚  2. Redis Cache (Upstash) â­                            â”‚
â”‚     â””â”€ Duration: 1-10 minutes                           â”‚
â”‚     â””â”€ Use: API responses, market data                  â”‚
â”‚                                                          â”‚
â”‚  3. Database Cache (PostgreSQL)                         â”‚
â”‚     â””â”€ Duration: 1 hour - 1 day                         â”‚
â”‚     â””â”€ Use: Historical data, analysis results           â”‚
â”‚                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Local Development                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                          â”‚
â”‚  SQLite (MCP Server)                                    â”‚
â”‚     â””â”€ Duration: Until cleared                          â”‚
â”‚     â””â”€ Use: Development convenience                     â”‚
â”‚     â””â”€ Location: data/cache.db                          â”‚
â”‚                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ’¡ Implementation Guide

### Step 1: Use Redis for Short-Term Cache (1-10 minutes)

**Install Upstash Redis SDK** (if not already):
```bash
npm install @upstash/redis
```

**Create Redis utility** (`lib/cache/redis.ts`):
```typescript
import { Redis } from '@upstash/redis';

const redis = new Redis({
  url: process.env.UPSTASH_REDIS_REST_URL!,
  token: process.env.UPSTASH_REDIS_REST_TOKEN!,
});

export async function getCached<T>(key: string): Promise<T | null> {
  try {
    return await redis.get<T>(key);
  } catch (error) {
    console.error('Redis get error:', error);
    return null;
  }
}

export async function setCache<T>(
  key: string, 
  value: T, 
  ttlSeconds: number = 300
): Promise<void> {
  try {
    await redis.set(key, value, { ex: ttlSeconds });
  } catch (error) {
    console.error('Redis set error:', error);
  }
}

export async function deleteCache(key: string): Promise<void> {
  try {
    await redis.del(key);
  } catch (error) {
    console.error('Redis delete error:', error);
  }
}
```

**Use in API routes**:
```typescript
import { getCached, setCache } from '@/lib/cache/redis';

export default async function handler(req, res) {
  const cacheKey = `btc:price:${Date.now() / 60000 | 0}`; // 1-minute buckets
  
  // Try cache first
  const cached = await getCached(cacheKey);
  if (cached) {
    return res.json({ ...cached, cached: true });
  }
  
  // Fetch fresh data
  const fresh = await fetchBTCPrice();
  
  // Cache for 5 minutes
  await setCache(cacheKey, fresh, 300);
  
  return res.json({ ...fresh, cached: false });
}
```

---

### Step 2: Use PostgreSQL for Long-Term Cache (1 hour - 1 day)

**Create cache table** (run migration):
```sql
-- migrations/002_api_cache.sql
CREATE TABLE IF NOT EXISTS api_cache (
  key TEXT PRIMARY KEY,
  value JSONB NOT NULL,
  created_at TIMESTAMP DEFAULT NOW(),
  expires_at TIMESTAMP NOT NULL
);

CREATE INDEX idx_api_cache_expires ON api_cache(expires_at);
CREATE INDEX idx_api_cache_created ON api_cache(created_at DESC);

-- Cleanup function
CREATE OR REPLACE FUNCTION cleanup_expired_cache()
RETURNS void AS $$
BEGIN
  DELETE FROM api_cache WHERE expires_at < NOW();
END;
$$ LANGUAGE plpgsql;
```

**Create database cache utility** (`lib/cache/database.ts`):
```typescript
import { query } from '@/lib/db';

export async function getDBCache<T>(key: string): Promise<T | null> {
  const result = await query(
    `SELECT value FROM api_cache 
     WHERE key = $1 AND expires_at > NOW()`,
    [key]
  );
  
  return result.rows[0]?.value || null;
}

export async function setDBCache<T>(
  key: string,
  value: T,
  ttlMinutes: number = 60
): Promise<void> {
  await query(
    `INSERT INTO api_cache (key, value, expires_at)
     VALUES ($1, $2, NOW() + INTERVAL '${ttlMinutes} minutes')
     ON CONFLICT (key) DO UPDATE 
     SET value = $2, expires_at = NOW() + INTERVAL '${ttlMinutes} minutes'`,
    [key, JSON.stringify(value)]
  );
}
```

---

## ğŸ¯ Cache Strategy by Data Type

### Market Prices (Use Redis):
- **TTL**: 1-5 minutes
- **Why**: Frequently accessed, needs to be fast
- **Example**: BTC/ETH current prices

### Historical Data (Use PostgreSQL):
- **TTL**: 1-24 hours
- **Why**: Doesn't change, can be stored longer
- **Example**: 30-day price history

### News Articles (Use Redis):
- **TTL**: 5-15 minutes
- **Why**: Updates frequently, needs to be fresh
- **Example**: Latest crypto news

### Whale Transactions (Use PostgreSQL):
- **TTL**: 1 hour - 1 day
- **Why**: Historical data, doesn't change
- **Example**: Analyzed whale transactions

### Social Sentiment (Use Redis):
- **TTL**: 5-10 minutes
- **Why**: Changes frequently, needs to be current
- **Example**: LunarCrush social scores

---

## âœ… Summary

### SQLite MCP Server:
- âœ… **Local development only**
- âœ… Works in Kiro IDE
- âŒ **NOT for Vercel production**
- âŒ **NOT deployed**

### Production Caching (Vercel):
- âœ… **Use Upstash Redis** (already configured)
- âœ… **Use PostgreSQL** (already configured)
- âŒ **Don't use SQLite**

### Your Current Setup:
- âœ… **Perfect for production!**
- âœ… Redis for rate limiting (working)
- âœ… PostgreSQL for data (working)
- âœ… SQLite for local dev (working)

---

## ğŸš€ Next Steps

1. âœ… Keep SQLite MCP server for local development
2. âœ… Use Upstash Redis for production caching
3. âœ… Use PostgreSQL for long-term cache
4. â³ Implement caching utilities (optional)
5. â³ Add cache to API endpoints (optional)

**No changes needed to your current setup!** Everything is configured correctly. SQLite is only for local development, and you have Redis + PostgreSQL for production. ğŸ‰

---

**Clarified**: November 8, 2025  
**Status**: âœ… Current setup is correct  
**Action**: No changes needed
