# OpenAI Integration Guide - Bitcoin Sovereign Technology

**Last Updated**: January 27, 2025  
**Status**: ‚úÖ Active - Production Ready  
**Scope**: Cryptocurrency analysis, trade signals, market intelligence  
**Primary API**: Chat Completions API  
**Models**: `chatgpt-4o-latest`, `gpt-5.1`

---

## üéØ Overview

This guide documents OpenAI integration patterns for the Bitcoin Sovereign Technology platform. We use OpenAI's Chat Completions API for cryptocurrency market analysis, trade signal generation, and intelligent data processing.

**Key Principle**: OpenAI is used for **analysis and insights**, not data fetching. Always fetch data first, then analyze with AI.

---

## üìä Current Implementation Status

### Models in Production

| Model | Use Cases | Status | Performance |
|-------|-----------|--------|-------------|
| `chatgpt-4o-latest` | UCIE modular analysis, news sentiment | ‚úÖ Primary | 800-1200ms |
| `gpt-5.1` | Quantum BTC, ATGE, deep analysis | ‚úÖ Production | 1500-3000ms |
| `gpt-4o` | Fallback, legacy endpoints | ‚úÖ Backup | 600-900ms |

### API Pattern

**We use Chat Completions API exclusively** (not Responses API):

```typescript
import OpenAI from 'openai';

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
  timeout: 120000, // 120 seconds
  maxRetries: 0    // We handle retries ourselves
});

const completion = await openai.chat.completions.create({
  model: 'chatgpt-4o-latest',
  messages: [
    { role: 'system', content: systemPrompt },
    { role: 'user', content: userPrompt }
  ],
  temperature: 0.7,
  max_tokens: 800,
  response_format: { type: 'json_object' } // For structured output
});
```

---

## üö® Critical Rules

### Rule #1: Data First, AI Second

**NEVER call OpenAI before data is ready.**

```typescript
// ‚ùå WRONG - AI called before data
const analysis = await openai.chat.completions.create({...});
const marketData = await fetchMarketData(); // Too late!

// ‚úÖ CORRECT - Data first, then AI
const marketData = await fetchMarketData();
const sentiment = await fetchSentiment();
const technical = await fetchTechnical();

// Now call AI with complete context
const analysis = await openai.chat.completions.create({
  model: 'chatgpt-4o-latest',
  messages: [
    { role: 'system', content: 'You are a crypto analyst...' },
    { role: 'user', content: `Analyze: ${JSON.stringify({marketData, sentiment, technical})}` }
  ]
});
```

### Rule #2: Use Utility Functions

**ALWAYS use our bulletproof extraction utilities:**

```typescript
import { extractResponseText, validateResponseText } from '../utils/openai';

const completion = await openai.chat.completions.create({...});

// ‚úÖ Bulletproof extraction (handles all edge cases)
const responseText = extractResponseText(completion, true); // true = debug mode
validateResponseText(responseText, 'chatgpt-4o-latest', completion);

// Now parse
const analysis = JSON.parse(responseText);
```

**Why?** These utilities handle:
- Missing `choices` array
- Null `message.content`
- Malformed JSON
- Empty responses
- API errors

### Rule #3: UCIE System Integration

**For UCIE features, follow the UCIE system rules:**

1. **AI Analysis Happens LAST** - Only after ALL data cached in database
2. **Database is Source of Truth** - Use `getCachedAnalysis()` and `setCachedAnalysis()`
3. **Data Quality Check** - Minimum 70% quality before AI analysis
4. **Context Aggregation** - Use `getComprehensiveContext()` for AI calls

**See**: `.kiro/steering/ucie-system.md` for complete UCIE documentation.

---

## üé® Model Selection Guide

### When to Use `chatgpt-4o-latest`

**Best for:**
- ‚úÖ Fast analysis (800-1200ms)
- ‚úÖ Modular analysis (market, technical, sentiment)
- ‚úÖ News sentiment classification
- ‚úÖ JSON output with `response_format`
- ‚úÖ Cost-effective at scale

**Use cases:**
- UCIE modular analysis (9 separate analyses)
- Bitcoin News Wire sentiment
- Quick trade signal validation

**Configuration:**
```typescript
const completion = await openai.chat.completions.create({
  model: 'chatgpt-4o-latest', // Auto-updates to latest GPT-4o
  messages: [...],
  temperature: 0.7,
  max_tokens: 800,
  response_format: { type: 'json_object' }
});
```

### When to Use `gpt-5.1`

**Best for:**
- ‚úÖ Deep reasoning (1500-3000ms)
- ‚úÖ Complex trade analysis
- ‚úÖ Multi-factor decision making
- ‚úÖ Strategic recommendations
- ‚úÖ High-stakes analysis

**Use cases:**
- Quantum BTC trade generation
- ATGE comprehensive analysis
- Deep dive whale analysis
- Risk assessment

**Configuration:**
```typescript
const completion = await openai.chat.completions.create({
  model: 'gpt-5.1',
  messages: [...],
  temperature: 0.7,
  max_tokens: 2000,
  // Note: gpt-5.1 doesn't support response_format yet
});
```

### Fallback Strategy

```typescript
const OPENAI_MODEL = process.env.OPENAI_MODEL || 'chatgpt-4o-latest';
const OPENAI_FALLBACK_MODEL = process.env.OPENAI_FALLBACK_MODEL || 'gpt-4o';

try {
  const completion = await openai.chat.completions.create({
    model: OPENAI_MODEL,
    messages: [...]
  });
} catch (error) {
  console.error('Primary model failed, trying fallback...');
  
  const completion = await openai.chat.completions.create({
    model: OPENAI_FALLBACK_MODEL,
    messages: [...]
  });
}
```

---

## üíª Implementation Patterns

### Pattern 1: UCIE Modular Analysis

**Use case**: Analyze specific data source (market, technical, sentiment, news)

```typescript
// pages/api/ucie/openai-summary-start/[symbol].ts

async function analyzeDataSource(
  dataType: string,
  dataToAnalyze: any,
  instructions: string
): Promise<any> {
  const model = process.env.OPENAI_MODEL || 'chatgpt-4o-latest';
  
  const prompt = `Analyze this ${dataType} data:

${JSON.stringify(dataToAnalyze, null, 2)}

${instructions}

Respond with valid JSON only.`;
  
  const completion = await openai.chat.completions.create({
    model: model,
    messages: [
      {
        role: 'system',
        content: `You are a cryptocurrency analyst. Analyze ${dataType} and respond with concise JSON.`
      },
      {
        role: 'user',
        content: prompt
      }
    ],
    temperature: 0.7,
    max_tokens: 800,
    response_format: { type: 'json_object' }
  });
  
  // ‚úÖ Bulletproof extraction
  const analysisText = extractResponseText(completion, true);
  validateResponseText(analysisText, model, completion);
  
  return JSON.parse(analysisText);
}
```

### Pattern 2: Trade Signal Generation

**Use case**: Generate actionable trade signals with confidence scores

```typescript
// pages/api/quantum/generate-btc-trade.ts

async function generateTradeSignal(
  marketData: any,
  technicalData: any,
  sentimentData: any
): Promise<TradeSignal> {
  const completion = await openai.chat.completions.create({
    model: 'gpt-5.1',
    messages: [
      {
        role: 'system',
        content: 'You are an expert cryptocurrency trader. Generate precise trade signals with risk management.'
      },
      {
        role: 'user',
        content: `Analyze this data and generate a trade signal:

Market: ${JSON.stringify(marketData)}
Technical: ${JSON.stringify(technicalData)}
Sentiment: ${JSON.stringify(sentimentData)}

Provide: signal (BUY/SELL/HOLD), confidence (0-100), entry price, stop loss, take profit levels, reasoning.`
      }
    ],
    temperature: 0.7,
    max_tokens: 2000
  });
  
  const responseText = extractResponseText(completion, true);
  validateResponseText(responseText, 'gpt-5.1', completion);
  
  // Parse and validate trade signal
  const signal = parseTradeSignal(responseText);
  return signal;
}
```

### Pattern 3: News Sentiment Analysis

**Use case**: Batch analyze news articles for sentiment

```typescript
// pages/api/bitcoin-news-wire.ts

async function analyzeNewsSentiment(articles: NewsArticle[]): Promise<SentimentResult[]> {
  const batchSize = 10;
  const results: SentimentResult[] = [];
  
  for (let i = 0; i < articles.length; i += batchSize) {
    const batch = articles.slice(i, i + batchSize);
    
    const completion = await openai.chat.completions.create({
      model: 'gpt-5.1',
      messages: [
        {
          role: 'system',
          content: 'You are a cryptocurrency news analyst. Classify sentiment as BULLISH, BEARISH, or NEUTRAL.'
        },
        {
          role: 'user',
          content: `Analyze sentiment for these articles:

${batch.map((a, idx) => `${idx + 1}. ${a.title}: ${a.description}`).join('\n\n')}

Respond with JSON array: [{"index": 1, "sentiment": "BULLISH", "confidence": 85, "reasoning": "..."}]`
        }
      ],
      temperature: 0.3, // Lower for consistent classification
      max_tokens: 1500,
      response_format: { type: 'json_object' }
    });
    
    const responseText = extractResponseText(completion, true);
    const batchResults = JSON.parse(responseText);
    results.push(...batchResults);
  }
  
  return results;
}
```

### Pattern 4: UCIE Complete Flow

**Use case**: Full UCIE analysis with data collection ‚Üí AI analysis

```typescript
// pages/api/ucie/openai-summary-start/[symbol].ts

export default async function handler(req, res) {
  const { symbol } = req.query;
  
  // ‚úÖ STEP 1: Fetch and cache ALL data first
  const [marketData, sentiment, technical, news, onChain] = await Promise.all([
    getCachedAnalysis(symbol, 'market-data'),
    getCachedAnalysis(symbol, 'sentiment'),
    getCachedAnalysis(symbol, 'technical'),
    getCachedAnalysis(symbol, 'news'),
    getCachedAnalysis(symbol, 'on-chain')
  ]);
  
  // ‚úÖ STEP 2: Verify data quality
  const dataQuality = calculateDataQuality({
    marketData, sentiment, technical, news, onChain
  });
  
  if (dataQuality < 70) {
    return res.status(400).json({
      error: 'Insufficient data quality for analysis',
      dataQuality
    });
  }
  
  // ‚úÖ STEP 3: Create analysis job
  const jobId = uuidv4();
  
  // Start background analysis
  analyzeInBackground(jobId, symbol, {
    marketData, sentiment, technical, news, onChain
  });
  
  return res.status(200).json({
    success: true,
    jobId,
    message: 'Analysis started'
  });
}

async function analyzeInBackground(jobId, symbol, data) {
  try {
    // Analyze each data source separately (modular approach)
    const analyses = await Promise.all([
      analyzeDataSource('market', data.marketData, 'Focus on price trends and volume'),
      analyzeDataSource('technical', data.technical, 'Focus on indicators and signals'),
      analyzeDataSource('sentiment', data.sentiment, 'Focus on market mood and social metrics'),
      analyzeDataSource('news', data.news, 'Focus on recent events and impact'),
      analyzeDataSource('on-chain', data.onChain, 'Focus on blockchain activity')
    ]);
    
    // Generate executive summary
    const summary = await generateExecutiveSummary(analyses);
    
    // Store complete analysis
    await setCachedAnalysis(symbol, 'openai-analysis', {
      jobId,
      analyses,
      summary,
      timestamp: new Date().toISOString()
    }, 3600, 100);
    
  } catch (error) {
    console.error('Analysis failed:', error);
    // Store error state
  }
}
```

---

## üéØ Prompt Engineering Best Practices

### System Prompts

**Be specific about role and output format:**

```typescript
// ‚úÖ GOOD - Clear role and expectations
{
  role: 'system',
  content: 'You are a cryptocurrency analyst specializing in Bitcoin. Analyze market data and provide actionable insights. Always respond with valid JSON containing: analysis, confidence, recommendation, risks.'
}

// ‚ùå BAD - Vague and generic
{
  role: 'system',
  content: 'You are a helpful assistant.'
}
```

### User Prompts

**Structure data clearly:**

```typescript
// ‚úÖ GOOD - Structured and clear
const prompt = `Analyze Bitcoin market conditions:

MARKET DATA:
- Price: $${price}
- 24h Change: ${change24h}%
- Volume: $${volume}

TECHNICAL INDICATORS:
- RSI: ${rsi}
- MACD: ${macd}
- Trend: ${trend}

TASK: Provide trade recommendation with confidence score and reasoning.`;

// ‚ùå BAD - Unstructured dump
const prompt = `Here's some data: ${JSON.stringify(allData)}. What should I do?`;
```

### JSON Output

**Use `response_format` for structured output:**

```typescript
const completion = await openai.chat.completions.create({
  model: 'chatgpt-4o-latest',
  messages: [...],
  response_format: { type: 'json_object' } // ‚úÖ Forces JSON output
});

// Prompt should still request JSON
const prompt = `Analyze and respond with JSON:
{
  "signal": "BUY" | "SELL" | "HOLD",
  "confidence": 0-100,
  "reasoning": "...",
  "risks": ["..."]
}`;
```

---

## ‚ö° Performance Optimization

### Timeout Configuration

```typescript
// Environment variables
OPENAI_TIMEOUT=120000        // 120 seconds (default)
FALLBACK_TIMEOUT=30000       // 30 seconds

// Implementation
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
  timeout: parseInt(process.env.OPENAI_TIMEOUT || '120000'),
  maxRetries: 0 // We handle retries ourselves
});
```

### Token Optimization

```typescript
// ‚úÖ GOOD - Concise prompts, focused output
max_tokens: 800  // For modular analysis
max_tokens: 2000 // For comprehensive analysis

// ‚ùå BAD - Excessive tokens
max_tokens: 8000 // Wastes tokens and money
```

### Parallel Processing

```typescript
// ‚úÖ GOOD - Analyze multiple sources in parallel
const analyses = await Promise.all([
  analyzeMarket(marketData),
  analyzeTechnical(technicalData),
  analyzeSentiment(sentimentData)
]);

// ‚ùå BAD - Sequential (slow)
const marketAnalysis = await analyzeMarket(marketData);
const technicalAnalysis = await analyzeTechnical(technicalData);
const sentimentAnalysis = await analyzeSentiment(sentimentData);
```

### Caching Strategy

```typescript
// Cache AI analysis results
await setCachedAnalysis(symbol, 'openai-analysis', result, 3600, 100);
// TTL: 3600 seconds (1 hour)
// Quality: 100 (AI analysis is always high quality)

// Check cache before calling OpenAI
const cached = await getCachedAnalysis(symbol, 'openai-analysis');
if (cached) {
  return cached; // Skip expensive API call
}
```

---

## üõ°Ô∏è Error Handling

### Comprehensive Error Handling

```typescript
async function callOpenAIWithRetry(
  messages: any[],
  maxRetries: number = 3
): Promise<any> {
  let lastError: Error;
  
  for (let attempt = 1; attempt <= maxRetries; attempt++) {
    try {
      const completion = await openai.chat.completions.create({
        model: process.env.OPENAI_MODEL || 'chatgpt-4o-latest',
        messages,
        temperature: 0.7,
        max_tokens: 800,
        timeout: 120000
      });
      
      const responseText = extractResponseText(completion, true);
      validateResponseText(responseText, 'chatgpt-4o-latest', completion);
      
      return JSON.parse(responseText);
      
    } catch (error) {
      lastError = error;
      console.error(`OpenAI attempt ${attempt}/${maxRetries} failed:`, error);
      
      // Don't retry on certain errors
      if (error.status === 401 || error.status === 403) {
        throw error; // Authentication errors
      }
      
      // Exponential backoff
      if (attempt < maxRetries) {
        const delay = Math.pow(2, attempt) * 1000;
        await new Promise(resolve => setTimeout(resolve, delay));
      }
    }
  }
  
  throw lastError;
}
```

### Graceful Degradation

```typescript
try {
  const analysis = await callOpenAI(data);
  return { success: true, analysis };
} catch (error) {
  console.error('OpenAI analysis failed:', error);
  
  // Return data without AI analysis
  return {
    success: true,
    analysis: null,
    data: data,
    message: 'Data available, AI analysis unavailable'
  };
}
```

---

## üìä Monitoring & Logging

### Request Logging

```typescript
console.log(`üöÄ [OpenAI] Starting analysis for ${symbol}`);
console.log(`üìä [OpenAI] Model: ${model}`);
console.log(`üìè [OpenAI] Prompt length: ${prompt.length} characters`);

const startTime = Date.now();
const completion = await openai.chat.completions.create({...});
const duration = Date.now() - startTime;

console.log(`‚úÖ [OpenAI] Completed in ${duration}ms`);
console.log(`üìä [OpenAI] Tokens used: ${completion.usage?.total_tokens}`);
```

### Cost Tracking

```typescript
interface OpenAIUsage {
  model: string;
  promptTokens: number;
  completionTokens: number;
  totalTokens: number;
  estimatedCost: number;
  timestamp: string;
}

function trackUsage(completion: any, model: string): OpenAIUsage {
  const usage = completion.usage;
  
  // Approximate costs (update based on current pricing)
  const costs = {
    'chatgpt-4o-latest': { input: 0.0025, output: 0.01 }, // per 1K tokens
    'gpt-5.1': { input: 0.005, output: 0.015 },
    'gpt-4o': { input: 0.0025, output: 0.01 }
  };
  
  const modelCost = costs[model] || costs['gpt-4o'];
  const estimatedCost = 
    (usage.prompt_tokens / 1000) * modelCost.input +
    (usage.completion_tokens / 1000) * modelCost.output;
  
  return {
    model,
    promptTokens: usage.prompt_tokens,
    completionTokens: usage.completion_tokens,
    totalTokens: usage.total_tokens,
    estimatedCost,
    timestamp: new Date().toISOString()
  };
}
```

---

## üß™ Testing

### Unit Tests

```typescript
// __tests__/api/openai-analysis.test.ts

describe('OpenAI Analysis', () => {
  it('should analyze market data successfully', async () => {
    const mockData = {
      price: 95000,
      change24h: 2.5,
      volume: 25000000000
    };
    
    const analysis = await analyzeMarket(mockData);
    
    expect(analysis).toHaveProperty('signal');
    expect(analysis).toHaveProperty('confidence');
    expect(analysis.confidence).toBeGreaterThanOrEqual(0);
    expect(analysis.confidence).toBeLessThanOrEqual(100);
  });
  
  it('should handle API errors gracefully', async () => {
    // Mock OpenAI error
    jest.spyOn(openai.chat.completions, 'create')
      .mockRejectedValue(new Error('API Error'));
    
    const result = await analyzeMarket({});
    
    expect(result.success).toBe(false);
    expect(result.error).toBeDefined();
  });
});
```

### Integration Tests

```typescript
// __tests__/integration/ucie-openai-flow.test.ts

describe('UCIE OpenAI Integration', () => {
  it('should complete full analysis flow', async () => {
    const symbol = 'BTC';
    
    // Step 1: Fetch data
    const data = await fetchAllData(symbol);
    expect(data.dataQuality).toBeGreaterThan(70);
    
    // Step 2: Start analysis
    const job = await startAnalysis(symbol, data);
    expect(job.jobId).toBeDefined();
    
    // Step 3: Poll for results
    const result = await pollForResults(job.jobId, 60);
    expect(result.status).toBe('completed');
    expect(result.analyses).toHaveLength(5);
  });
});
```

---

## üìã Environment Configuration

### Required Variables

```bash
# .env.local

# OpenAI API Key (REQUIRED)
OPENAI_API_KEY=sk-proj-...

# Model Configuration
OPENAI_MODEL=chatgpt-4o-latest
OPENAI_FALLBACK_MODEL=gpt-4o

# Timeout Configuration
OPENAI_TIMEOUT=120000
FALLBACK_TIMEOUT=30000

# Feature Flags
USE_REAL_AI_ANALYSIS=true
ENABLE_AI_NEWS_ANALYSIS=true
```

### Vercel Configuration

```json
// vercel.json
{
  "functions": {
    "pages/api/ucie/openai-summary-start/[symbol].ts": {
      "maxDuration": 300,
      "memory": 1024
    },
    "pages/api/quantum/generate-btc-trade.ts": {
      "maxDuration": 300,
      "memory": 1024
    }
  }
}
```

---

## üöÄ Deployment Checklist

Before deploying OpenAI features:

- [ ] `OPENAI_API_KEY` set in Vercel environment variables
- [ ] Model configuration verified (`OPENAI_MODEL`, `OPENAI_FALLBACK_MODEL`)
- [ ] Timeout values appropriate for Vercel plan (30s free, 300s Pro)
- [ ] Error handling implemented with graceful degradation
- [ ] Caching strategy in place to reduce API calls
- [ ] Logging and monitoring configured
- [ ] Cost tracking implemented
- [ ] Tests passing (unit + integration)
- [ ] UCIE system rules followed (if applicable)

---

## üìö Additional Resources

### Internal Documentation
- **UCIE System**: `.kiro/steering/ucie-system.md`
- **API Integration**: `.kiro/steering/api-integration.md`
- **Utility Functions**: `utils/openai.ts`

### OpenAI Documentation
- **Chat Completions API**: https://platform.openai.com/docs/api-reference/chat
- **Models**: https://platform.openai.com/docs/models
- **Best Practices**: https://platform.openai.com/docs/guides/prompt-engineering

### Project Examples
- **UCIE Modular Analysis**: `pages/api/ucie/openai-summary-start/[symbol].ts`
- **Trade Generation**: `pages/api/quantum/generate-btc-trade.ts`
- **News Sentiment**: `pages/api/bitcoin-news-wire.ts`

---

**Status**: ‚úÖ Production Ready  
**Last Updated**: January 27, 2025  
**Models**: `chatgpt-4o-latest` (primary), `gpt-5.1` (deep analysis)  
**API**: Chat Completions API

**Remember**: Data first, AI second. Always fetch and cache data before calling OpenAI!
