# Vercel Timeout Fix - 3 Solutions

**Error**: Vercel Runtime Timeout (30 seconds) on `/api/ucie/preview-data/BTC`  
**Root Cause**: Authentication requirement + sequential API calls + database writes  
**Created**: January 27, 2025

---

## ğŸ” Deep Dive Analysis

### Current Issues

1. **Authentication Bottleneck**
   - `setCachedAnalysis()` REQUIRES `userEmail` and `userId`
   - Anonymous users skip caching â†’ repeated API calls
   - Preview endpoint doesn't pass authentication â†’ no caching

2. **Sequential Processing**
   - Fetch 5 APIs in parallel (10-30s)
   - Write 5 database entries sequentially (2-5s)
   - Generate OpenAI summary (3-10s)
   - **Total**: 15-45 seconds (exceeds 30s limit)

3. **Database Write Blocking**
   - All 5 `setCachedAnalysis()` calls must complete before OpenAI
   - If user not authenticated, all writes skipped
   - No fallback caching mechanism

4. **No Data Persistence for Anonymous**
   - Anonymous users get NO caching
   - Every request fetches fresh data
   - Increases timeout risk

### User Requirements

âœ… 100% live/most recent data  
âœ… No errors on data retrieval  
âœ… Store data in Supabase (overwrite if exists)  
âœ… All data sources supply data  
âœ… User login tracked in database (not in API calls)  

---

## ğŸ¯ Solution 1: System User Fallback (RECOMMENDED)

### Concept
Create a "system" user for anonymous requests, allowing database caching while tracking real users separately.

### Implementation

**1. Create System User in Database**
```sql
-- Add system user for anonymous caching
INSERT INTO users (id, email, created_at)
VALUES ('system-cache', 'system@arcane.group', NOW())
ON CONFLICT (id) DO NOTHING;
```

**2. Update `setCachedAnalysis()`**
```typescript
export async function setCachedAnalysis(
  symbol: string,
  analysisType: AnalysisType,
  data: any,
  ttlSeconds: number = 86400,
  dataQualityScore?: number,
  userId?: string,
  userEmail?: string
): Promise<void> {
  try {
    // âœ… FALLBACK: Use system user for anonymous requests
    const effectiveUserId = userId || 'system-cache';
    const effectiveUserEmail = userEmail || 'system@arcane.group';
    
    // âœ… ALWAYS cache (authenticated or system user)
    console.log(`ğŸ” Caching for ${userId ? 'authenticated' : 'system'} user: ${effectiveUserId} <${effectiveUserEmail}>`);
    
    await query(
      `INSERT INTO ucie_analysis_cache (
        symbol, analysis_type, data, data_quality_score, user_id, user_email, expires_at, created_at
      ) VALUES ($1, $2, $3, $4, $5, $6, NOW() + INTERVAL '${ttlSeconds} seconds', NOW())
      ON CONFLICT (symbol, analysis_type)
      DO UPDATE SET
        data = EXCLUDED.data,
        data_quality_score = EXCLUDED.data_quality_score,
        user_id = EXCLUDED.user_id,
        user_email = EXCLUDED.user_email,
        expires_at = EXCLUDED.expires_at,
        created_at = NOW()`,
      [
        symbol.toUpperCase(),
        analysisType,
        JSON.stringify(data),
        dataQualityScore || null,
        effectiveUserId,
        effectiveUserEmail
      ]
    );
    
    console.log(`âœ… Analysis cached for ${symbol}/${analysisType} (user: ${effectiveUserEmail}, TTL: ${ttlSeconds}s)`);
  } catch (error) {
    console.error(`âŒ Failed to cache analysis for ${symbol}/${analysisType}:`, error);
    // âœ… NON-BLOCKING: Don't throw error, just log it
    // This prevents timeout if database write fails
  }
}
```

**3. Update Preview Endpoint**
```typescript
// No changes needed - system user fallback handles it automatically
```

### Pros
âœ… **No timeout risk** - All requests get cached  
âœ… **Backward compatible** - Existing code works  
âœ… **Tracks real users** - Authenticated users still tracked separately  
âœ… **Simple implementation** - Minimal code changes  
âœ… **Caesar AI works** - Always has data in database  

### Cons
âš ï¸ System user data mixed with real user data  
âš ï¸ Can't distinguish anonymous vs authenticated in database  
âš ï¸ May need periodic cleanup of system user data  

### Deployment Steps
1. Run SQL to create system user
2. Update `lib/ucie/cacheUtils.ts`
3. Test with anonymous request
4. Deploy to production
5. Monitor cache hit rates

---

## ğŸ¯ Solution 2: Async Background Processing

### Concept
Make database writes non-blocking by using background jobs, allowing preview endpoint to return immediately.

### Implementation

**1. Create Background Job Queue**
```typescript
// lib/ucie/backgroundQueue.ts
interface CacheJob {
  symbol: string;
  analysisType: AnalysisType;
  data: any;
  ttlSeconds: number;
  dataQualityScore?: number;
  userId?: string;
  userEmail?: string;
}

const cacheQueue: CacheJob[] = [];
let processing = false;

export function queueCacheWrite(job: CacheJob) {
  cacheQueue.push(job);
  if (!processing) {
    processQueue();
  }
}

async function processQueue() {
  processing = true;
  
  while (cacheQueue.length > 0) {
    const job = cacheQueue.shift();
    if (!job) continue;
    
    try {
      await setCachedAnalysis(
        job.symbol,
        job.analysisType,
        job.data,
        job.ttlSeconds,
        job.dataQualityScore,
        job.userId,
        job.userEmail
      );
    } catch (error) {
      console.error('Background cache write failed:', error);
    }
  }
  
  processing = false;
}
```

**2. Update Preview Endpoint**
```typescript
// Queue database writes instead of awaiting them
if (collectedData.marketData?.success) {
  queueCacheWrite({
    symbol: normalizedSymbol,
    analysisType: 'market-data',
    data: collectedData.marketData,
    ttlSeconds: 15 * 60,
    dataQualityScore: collectedData.marketData.dataQuality || 0,
    userId,
    userEmail
  });
}

// Continue immediately without waiting
const summary = await generateOpenAISummary(normalizedSymbol, collectedData, apiStatus);
```

**3. Update `setCachedAnalysis()`**
```typescript
// Make non-blocking (don't throw errors)
export async function setCachedAnalysis(...) {
  try {
    // ... existing code
  } catch (error) {
    console.error('Cache write failed:', error);
    // Don't throw - just log
  }
}
```

### Pros
âœ… **Fast response** - No waiting for database writes  
âœ… **No timeout risk** - Returns within 10-15 seconds  
âœ… **Scalable** - Can handle high traffic  
âœ… **Resilient** - Failures don't block response  

### Cons
âš ï¸ **Complex** - Requires queue management  
âš ï¸ **Race conditions** - OpenAI might read before write completes  
âš ï¸ **No guarantee** - Data might not be in database when needed  
âš ï¸ **Serverless issues** - Queue lost on function restart  

### Deployment Steps
1. Create background queue module
2. Update preview endpoint to use queue
3. Update setCachedAnalysis to be non-blocking
4. Test thoroughly for race conditions
5. Deploy with monitoring

---

## ğŸ¯ Solution 3: Increase Timeout + Optimize (HYBRID)

### Concept
Increase Vercel timeout limit AND optimize code to reduce execution time.

### Implementation

**1. Increase Vercel Timeout**
```typescript
// pages/api/ucie/preview-data/[symbol].ts
export const config = {
  api: {
    responseLimit: false,
    bodyParser: {
      sizeLimit: '1mb',
    },
  },
  maxDuration: 60, // âœ… Increase to 60 seconds (Vercel Pro plan)
};
```

**2. Optimize Database Writes (Parallel)**
```typescript
// Write all 5 entries in parallel (not sequential)
const storagePromises = [];

if (collectedData.marketData?.success) {
  storagePromises.push(
    setCachedAnalysis(normalizedSymbol, 'market-data', collectedData.marketData, 15 * 60, collectedData.marketData.dataQuality || 0, userId, userEmail)
  );
}

// ... add all 5 promises

// âœ… Wait for ALL in parallel (2-3s instead of 10-15s)
await Promise.allSettled(storagePromises);
```

**3. Add System User Fallback**
```typescript
// Combine with Solution 1 for best results
const effectiveUserId = userId || 'system-cache';
const effectiveUserEmail = userEmail || 'system@arcane.group';
```

**4. Optimize OpenAI Call**
```typescript
// Reduce max_tokens to speed up response
const completion = await openai.chat.completions.create({
  model: 'gpt-4o',
  messages: [...],
  temperature: 0.7,
  max_tokens: 300, // âœ… Reduced from 500
  timeout: 10000 // âœ… Add 10s timeout
});
```

**5. Add Caching for Preview**
```typescript
// Cache the entire preview response
const cacheKey = `preview-${normalizedSymbol}`;
const cached = await getCachedAnalysis(normalizedSymbol, 'preview-data' as AnalysisType);

if (cached && !refresh) {
  return res.status(200).json({
    success: true,
    data: cached,
    cached: true
  });
}
```

### Pros
âœ… **Comprehensive** - Addresses multiple issues  
âœ… **Reliable** - Multiple optimizations reduce risk  
âœ… **Best performance** - Parallel writes + caching  
âœ… **Backward compatible** - Works with existing code  
âœ… **Future-proof** - Can handle more data sources  

### Cons
âš ï¸ **Requires Vercel Pro** - 60s timeout needs paid plan  
âš ï¸ **More complex** - Multiple changes needed  
âš ï¸ **Testing required** - Need to verify all optimizations work  

### Deployment Steps
1. Upgrade to Vercel Pro (if needed)
2. Update config to 60s timeout
3. Optimize database writes (parallel)
4. Add system user fallback
5. Optimize OpenAI call
6. Add preview caching
7. Test thoroughly
8. Deploy with monitoring

---

## ğŸ“Š Comparison Matrix

| Feature | Solution 1 (System User) | Solution 2 (Async Queue) | Solution 3 (Hybrid) |
|---------|-------------------------|--------------------------|---------------------|
| **Complexity** | ğŸŸ¢ Low | ğŸ”´ High | ğŸŸ¡ Medium |
| **Timeout Risk** | ğŸŸ¢ Low | ğŸŸ¢ Very Low | ğŸŸ¢ Very Low |
| **Data Reliability** | ğŸŸ¢ High | ğŸŸ¡ Medium | ğŸŸ¢ High |
| **Cost** | ğŸŸ¢ Free | ğŸŸ¢ Free | ğŸŸ¡ Vercel Pro |
| **Implementation Time** | ğŸŸ¢ 1 hour | ğŸ”´ 4-6 hours | ğŸŸ¡ 2-3 hours |
| **Maintenance** | ğŸŸ¢ Low | ğŸ”´ High | ğŸŸ¡ Medium |
| **Scalability** | ğŸŸ¡ Medium | ğŸŸ¢ High | ğŸŸ¢ High |
| **Caesar AI Compatible** | ğŸŸ¢ Yes | ğŸŸ¡ Maybe | ğŸŸ¢ Yes |

---

## ğŸ¯ Recommendation

### **Solution 1: System User Fallback** (RECOMMENDED)

**Why?**
- âœ… Simplest to implement (1 hour)
- âœ… Lowest risk (minimal code changes)
- âœ… Solves timeout issue immediately
- âœ… Works with existing infrastructure
- âœ… Caesar AI gets data reliably
- âœ… No additional costs

**Implementation Priority**:
1. Create system user in database (5 min)
2. Update `setCachedAnalysis()` (15 min)
3. Test with anonymous request (10 min)
4. Deploy to production (5 min)
5. Monitor for 24 hours

**Fallback Plan**:
If Solution 1 doesn't fully resolve timeout, implement Solution 3 optimizations incrementally.

---

## ğŸš€ Quick Start (Solution 1)

### Step 1: Create System User
```bash
# Run this SQL in Supabase
npx tsx -e "
import { query } from './lib/db';
await query(\`
  INSERT INTO users (id, email, created_at)
  VALUES ('system-cache', 'system@arcane.group', NOW())
  ON CONFLICT (id) DO NOTHING
\`);
console.log('âœ… System user created');
"
```

### Step 2: Update cacheUtils.ts
```typescript
// Replace lines 85-95 in lib/ucie/cacheUtils.ts
const effectiveUserId = userId || 'system-cache';
const effectiveUserEmail = userEmail || 'system@arcane.group';

console.log(`ğŸ” Caching for ${userId ? 'authenticated' : 'system'} user: ${effectiveUserId} <${effectiveUserEmail}>`);
```

### Step 3: Make Non-Blocking
```typescript
// Replace line 120 in lib/ucie/cacheUtils.ts
} catch (error) {
  console.error(`âŒ Failed to cache analysis for ${symbol}/${analysisType}:`, error);
  // Don't throw - just log (non-blocking)
}
```

### Step 4: Test
```bash
curl https://news.arcane.group/api/ucie/preview-data/BTC
```

### Step 5: Deploy
```bash
git add -A
git commit -m "fix(ucie): Add system user fallback to prevent timeout"
git push origin main
```

---

**Choose your solution and I'll implement it immediately!** ğŸš€
